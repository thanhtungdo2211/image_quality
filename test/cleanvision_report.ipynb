{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cleanvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from PIL import ImageStat, ImageFilter\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "from typing import List, Dict, Any\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brightness Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "light_score =1 - per_cal(5)\n",
    "\n",
    "dark_score = per_cal(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_brightness(\n",
    "    red: Union[float, \"np.ndarray[Any, Any]\"],\n",
    "    green: Union[float, \"np.ndarray[Any, Any]\"],\n",
    "    blue: Union[float, \"np.ndarray[Any, Any]\"],\n",
    ") -> Union[float, \"np.ndarray[Any, Any]\"]:\n",
    "    cur_bright = (\n",
    "        np.sqrt(0.241 * (red * red) + 0.691 * (green * green) + 0.068 * (blue * blue))\n",
    "    ) / 255\n",
    "\n",
    "    return cur_bright\n",
    "def calc_avg_brightness(image: Image) -> float:\n",
    "    stat = ImageStat.Stat(image)\n",
    "    try:\n",
    "        red, green, blue = stat.mean\n",
    "        # print(red, green, blue)\n",
    "    except ValueError:\n",
    "        red, green, blue = (\n",
    "            stat.mean[0],\n",
    "            stat.mean[0],\n",
    "            stat.mean[0],\n",
    "        )  # deals with black and white images\n",
    "    cur_bright: float = calculate_brightness(red, green, blue)\n",
    "    return cur_bright\n",
    "def calc_percentile_brightness(\n",
    "    image: Image, percentiles: List[int]\n",
    ") -> \"np.ndarray[Any, Any]\":\n",
    "    imarr = np.asarray(image)\n",
    "    if len(imarr.shape) == 3:\n",
    "        r, g, b = (\n",
    "            imarr[:, :, 0].astype(\"int\"),\n",
    "            imarr[:, :, 1].astype(\"int\"),\n",
    "            imarr[:, :, 2].astype(\"int\"),\n",
    "        )\n",
    "        pixel_brightness = calculate_brightness(\n",
    "            r, g, b\n",
    "        )  # np.sqrt(0.241 * r * r + 0.691 * g * g + 0.068 * b * b)\n",
    "    else:\n",
    "        pixel_brightness = imarr / 255.0\n",
    "    perc_values: \"np.ndarray[Any, Any]\" = np.percentile(pixel_brightness, percentiles)\n",
    "    return perc_values\n",
    "\n",
    "def calculate_brightness_score(image: Image) -> Dict[str, Union[float, str]]:\n",
    "        percentiles = [1, 5, 10, 15, 90, 95, 99]\n",
    "        perc_values = calc_percentile_brightness(image, percentiles=percentiles)\n",
    "        raw_values = {\n",
    "            f\"brightness_perc_{p}\": value for p, value in zip(percentiles, perc_values)\n",
    "        }\n",
    "        raw_values[\"brightness\"] = calc_avg_brightness(image)\n",
    "        return raw_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_brightness : 0.447781200317847\n",
      "per_brightness : [0.12905143 0.25272759 0.30606882 0.33616486 0.59083415 0.61968549\n",
      " 0.66514291]\n",
      "raw_value : {'brightness_perc_1': 0.12905142941503522, 'brightness_perc_5': 0.25272758880010526, 'brightness_perc_10': 0.30606882199684926, 'brightness_perc_15': 0.33616485950247893, 'brightness_perc_90': 0.590834154461015, 'brightness_perc_95': 0.6196854878131554, 'brightness_perc_99': 0.6651429068291944, 'brightness': 0.447781200317847}\n"
     ]
    }
   ],
   "source": [
    "gray_image = Image.open('/media/tung/New Volume/Ubuntu/Programing/MQ Solutions/Task Data/data quality/dermet_image_train/03AnalExcoriation051204.jpg')\n",
    "avg_brightness = calc_avg_brightness(gray_image)\n",
    "print(\"avg_brightness :\", avg_brightness)\n",
    "\n",
    "per_brightness = calc_percentile_brightness(gray_image, [1, 5, 10, 15, 90, 95, 99])\n",
    "print(\"per_brightness :\", per_brightness)\n",
    "\n",
    "raw_values = calculate_brightness_score(image = gray_image)\n",
    "print(\"raw_value :\", raw_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aspect Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aspect_ratio_score = min(width / height, height / width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_aspect_ratio_score(image: Image) -> float:\n",
    "    width, height = image.size\n",
    "    size_score = min(width / height, height / width)  # consider extreme shapes\n",
    "    assert isinstance(size_score, float)\n",
    "    return size_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "low_information_score = entropyscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy_score(image: Image) -> float:\n",
    "    entropy = image.entropy()\n",
    "    assert isinstance(\n",
    "        entropy, float\n",
    "    )  # PIL does not have type ann stub so need to assert function return\n",
    "    return entropy/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blurriness Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "blurriness_score = minimum(blur_scores + std_scores, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RESOLUTION_FOR_BLURRY_DETECTION = 64\n",
    "def get_edges(gray_image: Image) -> Image:\n",
    "    edges = gray_image.filter(ImageFilter.FIND_EDGES)\n",
    "    return edges\n",
    "\n",
    "def calc_blurriness(gray_image: Image) -> float:\n",
    "    edges = get_edges(gray_image)\n",
    "    blurriness = ImageStat.Stat(edges).var[0]\n",
    "    return np.sqrt(blurriness)  # type:ignore\n",
    "\n",
    "def calc_std_grayscale(gray_image: Image) -> float:\n",
    "    return np.std(gray_image.histogram())  # type: ignore\n",
    "\n",
    "def calculate_blurriness_score(image: Image) -> Dict[str, Union[float, str]]:\n",
    "    ratio = max(image.width, image.height) / MAX_RESOLUTION_FOR_BLURRY_DETECTION\n",
    "    if ratio > 1:\n",
    "        resized_image = image.resize(\n",
    "            (max(int(image.width // ratio), 1), max(int(image.height // ratio), 1))\n",
    "        )\n",
    "    else:\n",
    "        resized_image = image.copy()\n",
    "    gray_image = resized_image.convert(\"L\")\n",
    "    blur_scores = 1 - np.exp(-1 * calc_blurriness(gray_image) / 100)\n",
    "    std_scores = 1 - np.exp(\n",
    "            -1 * calc_std_grayscale(gray_image) / 100\n",
    "    )\n",
    "    blur_std_score = np.minimum(blur_scores + std_scores, 1)\n",
    "    return {\n",
    "        # \"blurriness_score\": calc_blurriness(gray_image),\n",
    "        # \"blurriness_grayscale_std\": calc_std_grayscale(gray_image),\n",
    "        \"score\" : blur_std_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ColorSpace Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grayscale_score = 1 if RGB, else = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_color_space(image: Image) -> str:\n",
    "    return get_image_mode(image)\n",
    "\n",
    "def get_image_mode(image: Image) -> str:\n",
    "    if image.mode:\n",
    "        image_mode = image.mode\n",
    "        assert isinstance(image_mode, str)\n",
    "        return image_mode\n",
    "    else:\n",
    "        imarr = np.asarray(image)\n",
    "        if len(imarr.shape) == 2 or (\n",
    "            len(imarr.shape) == 3\n",
    "            and (np.diff(imarr.reshape(-1, 3).T, axis=0) == 0).all()\n",
    "        ):\n",
    "            return \"L\"\n",
    "        else:\n",
    "            return \"UNK\"\n",
    "\n",
    "def calculate_space_color(image: Image) -> Dict[str, Union[float, str]]:\n",
    "    return 1 if calc_color_space(image) == \"RGB\" else 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_image_area_sqrt(image: Image) -> float:\n",
    "    w, h = image.size\n",
    "    return math.sqrt(w) * math.sqrt(h)\n",
    "\n",
    "def get_image_area_sqrt_sizes(folder_path: str) -> list:\n",
    "    image_sqrt_sizes = []\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "            try:\n",
    "                with Image.open(os.path.join(folder_path, file_name)) as img:\n",
    "                    image_sqrt_size = calc_image_area_sqrt(img)\n",
    "                    image_sqrt_sizes.append(image_sqrt_size)\n",
    "            except IOError:\n",
    "                print(f\"Cannot open {file_name}.\")\n",
    "    return image_sqrt_sizes\n",
    "\n",
    "def calculate_image_size_score(image: Image, folderpath: str, iqr_factor: float = 3.0) -> float:\n",
    "    image_sizes = get_image_area_sqrt_sizes(folderpath)\n",
    "\n",
    "    q1, q3 = np.percentile(image_sizes, [25, 75])\n",
    "    iqr = q3 - q1\n",
    "    min_threshold = q1 - iqr_factor * iqr\n",
    "    max_threshold = q3 + iqr_factor * iqr\n",
    "    mid_threshold = (min_threshold + max_threshold) / 2\n",
    "\n",
    "    image_size = calc_image_area_sqrt(image)\n",
    "    distance = abs(image_size - mid_threshold)\n",
    "    norm_value = max_threshold - min_threshold if max_threshold - min_threshold > 0 else mid_threshold\n",
    "    norm_dist = distance / norm_value\n",
    "    score_value = 1 - np.clip(norm_dist, 0, 1)\n",
    "    \n",
    "    return score_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Near Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using P hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: frame_check_13500.jpg have 7 Duplicates image : ['frame_check_9600.jpg', 'frame_check_17670.jpg', 'frame_check_17730.jpg', 'frame_check_13050.jpg', 'frame_check_12960.jpg', 'frame_check_12990.jpg', 'frame_check_13020.jpg']\n",
      "Image: frame_check_20190.jpg have 19 Duplicates image : ['frame_check_20310.jpg', 'frame_check_20340.jpg', 'frame_check_20430.jpg', 'frame_check_20610.jpg', 'frame_check_8880.jpg', 'frame_check_8820.jpg', 'frame_check_8850.jpg', 'frame_check_5550.jpg', 'frame_check_20010.jpg', 'frame_check_20040.jpg', 'frame_check_20100.jpg', 'frame_check_20130.jpg', 'frame_check_8040.jpg', 'frame_check_8160.jpg', 'frame_check_8190.jpg', 'frame_check_8220.jpg', 'frame_check_8250.jpg', 'frame_check_20820.jpg', 'frame_check_21030.jpg']\n",
      "Image: frame_check_20220.jpg have 2 Duplicates image : ['frame_check_7380.jpg', 'frame_check_20970.jpg']\n",
      "Image: frame_check_20250.jpg have 5 Duplicates image : ['frame_check_20370.jpg', 'frame_check_20400.jpg', 'frame_check_20640.jpg', 'frame_check_26730.jpg', 'frame_check_18960.jpg']\n",
      "Image: frame_check_20280.jpg have 3 Duplicates image : ['frame_check_25650.jpg', 'frame_check_25710.jpg', 'frame_check_20070.jpg']\n",
      "Image: frame_check_20490.jpg have 1 Duplicates image : ['frame_check_20520.jpg']\n",
      "Image: frame_check_20550.jpg have 1 Duplicates image : ['frame_check_20580.jpg']\n",
      "Image: frame_check_20670.jpg have 34 Duplicates image : ['frame_check_26340.jpg', 'frame_check_27060.jpg', 'frame_check_6030.jpg', 'frame_check_26370.jpg', 'frame_check_26400.jpg', 'frame_check_26430.jpg', 'frame_check_26460.jpg', 'frame_check_26490.jpg', 'frame_check_26520.jpg', 'frame_check_26550.jpg', 'frame_check_26580.jpg', 'frame_check_26760.jpg', 'frame_check_26790.jpg', 'frame_check_26820.jpg', 'frame_check_25410.jpg', 'frame_check_25440.jpg', 'frame_check_25530.jpg', 'frame_check_19200.jpg', 'frame_check_19230.jpg', 'frame_check_19260.jpg', 'frame_check_19350.jpg', 'frame_check_19380.jpg', 'frame_check_19410.jpg', 'frame_check_26220.jpg', 'frame_check_26250.jpg', 'frame_check_27120.jpg', 'frame_check_27150.jpg', 'frame_check_27180.jpg', 'frame_check_27210.jpg', 'frame_check_27240.jpg', 'frame_check_27270.jpg', 'frame_check_27300.jpg', 'frame_check_27330.jpg', 'frame_check_27420.jpg']\n",
      "Image: frame_check_2070.jpg have 3 Duplicates image : ['frame_check_2130.jpg', 'frame_check_1980.jpg', 'frame_check_2100.jpg']\n",
      "Image: frame_check_28740.jpg have 12 Duplicates image : ['frame_check_8310.jpg', 'frame_check_8340.jpg', 'frame_check_8790.jpg', 'frame_check_19980.jpg', 'frame_check_8910.jpg', 'frame_check_8970.jpg', 'frame_check_9000.jpg', 'frame_check_8070.jpg', 'frame_check_8100.jpg', 'frame_check_8130.jpg', 'frame_check_8280.jpg', 'frame_check_20790.jpg']\n",
      "Image: frame_check_28770.jpg have 17 Duplicates image : ['frame_check_22500.jpg', 'frame_check_22950.jpg', 'frame_check_21660.jpg', 'frame_check_23010.jpg', 'frame_check_23040.jpg', 'frame_check_23070.jpg', 'frame_check_23100.jpg', 'frame_check_23130.jpg', 'frame_check_23160.jpg', 'frame_check_23190.jpg', 'frame_check_23220.jpg', 'frame_check_21750.jpg', 'frame_check_21840.jpg', 'frame_check_21930.jpg', 'frame_check_22980.jpg', 'frame_check_18870.jpg', 'frame_check_20730.jpg']\n",
      "Image: frame_check_28800.jpg have 9 Duplicates image : ['frame_check_28830.jpg', 'frame_check_15420.jpg', 'frame_check_21810.jpg', 'frame_check_19710.jpg', 'frame_check_19770.jpg', 'frame_check_19800.jpg', 'frame_check_19830.jpg', 'frame_check_19860.jpg', 'frame_check_19890.jpg']\n",
      "Image: frame_check_28890.jpg have 4 Duplicates image : ['frame_check_26940.jpg', 'frame_check_25380.jpg', 'frame_check_26280.jpg', 'frame_check_26310.jpg']\n",
      "Image: frame_check_28920.jpg have 3 Duplicates image : ['frame_check_12360.jpg', 'frame_check_12450.jpg', 'frame_check_12480.jpg']\n",
      "Image: frame_check_2910.jpg have 11 Duplicates image : ['frame_check_3120.jpg', 'frame_check_3000.jpg', 'frame_check_3030.jpg', 'frame_check_3150.jpg', 'frame_check_3180.jpg', 'frame_check_3210.jpg', 'frame_check_3240.jpg', 'frame_check_3060.jpg', 'frame_check_3090.jpg', 'frame_check_2940.jpg', 'frame_check_2970.jpg']\n",
      "Image: frame_check_29220.jpg have 1 Duplicates image : ['frame_check_30570.jpg']\n",
      "Image: frame_check_14790.jpg have 2 Duplicates image : ['frame_check_22710.jpg', 'frame_check_24720.jpg']\n",
      "Image: frame_check_14850.jpg have 20 Duplicates image : ['frame_check_14880.jpg', 'frame_check_15270.jpg', 'frame_check_13080.jpg', 'frame_check_13110.jpg', 'frame_check_13140.jpg', 'frame_check_13380.jpg', 'frame_check_13410.jpg', 'frame_check_13440.jpg', 'frame_check_13470.jpg', 'frame_check_14010.jpg', 'frame_check_14070.jpg', 'frame_check_12390.jpg', 'frame_check_12510.jpg', 'frame_check_12540.jpg', 'frame_check_12570.jpg', 'frame_check_12600.jpg', 'frame_check_12630.jpg', 'frame_check_12660.jpg', 'frame_check_12690.jpg', 'frame_check_12720.jpg']\n",
      "Image: frame_check_14970.jpg have 19 Duplicates image : ['frame_check_22410.jpg', 'frame_check_13170.jpg', 'frame_check_13200.jpg', 'frame_check_13230.jpg', 'frame_check_13260.jpg', 'frame_check_13290.jpg', 'frame_check_13320.jpg', 'frame_check_13350.jpg', 'frame_check_15360.jpg', 'frame_check_15450.jpg', 'frame_check_15480.jpg', 'frame_check_15510.jpg', 'frame_check_15840.jpg', 'frame_check_22320.jpg', 'frame_check_14040.jpg', 'frame_check_14160.jpg', 'frame_check_14190.jpg', 'frame_check_22380.jpg', 'frame_check_15960.jpg']\n",
      "Image: frame_check_1500.jpg have 7 Duplicates image : ['frame_check_1530.jpg', 'frame_check_1350.jpg', 'frame_check_1380.jpg', 'frame_check_1410.jpg', 'frame_check_1440.jpg', 'frame_check_1470.jpg', 'frame_check_1290.jpg']\n",
      "Image: frame_check_15000.jpg have 1 Duplicates image : ['frame_check_15810.jpg']\n",
      "Image: frame_check_15060.jpg have 3 Duplicates image : ['frame_check_15900.jpg', 'frame_check_15930.jpg', 'frame_check_15990.jpg']\n",
      "Image: frame_check_15120.jpg have 4 Duplicates image : ['frame_check_18030.jpg', 'frame_check_17520.jpg', 'frame_check_17550.jpg', 'frame_check_25770.jpg']\n",
      "Image: frame_check_15180.jpg have 1 Duplicates image : ['frame_check_23580.jpg']\n",
      "Image: frame_check_15210.jpg have 1 Duplicates image : ['frame_check_15240.jpg']\n",
      "Image: frame_check_23910.jpg have 1 Duplicates image : ['frame_check_23940.jpg']\n",
      "Image: frame_check_23970.jpg have 1 Duplicates image : ['frame_check_24000.jpg']\n",
      "Image: frame_check_24210.jpg have 1 Duplicates image : ['frame_check_24240.jpg']\n",
      "Image: frame_check_2430.jpg have 2 Duplicates image : ['frame_check_2340.jpg', 'frame_check_2370.jpg']\n",
      "Image: frame_check_24480.jpg have 2 Duplicates image : ['frame_check_18450.jpg', 'frame_check_23760.jpg']\n",
      "Image: frame_check_24510.jpg have 7 Duplicates image : ['frame_check_19140.jpg', 'frame_check_21300.jpg', 'frame_check_21330.jpg', 'frame_check_21360.jpg', 'frame_check_21390.jpg', 'frame_check_21510.jpg', 'frame_check_23310.jpg']\n",
      "Image: frame_check_25590.jpg have 3 Duplicates image : ['frame_check_20160.jpg', 'frame_check_27390.jpg', 'frame_check_9030.jpg']\n",
      "Image: frame_check_31440.jpg have 13 Duplicates image : ['frame_check_6960.jpg', 'frame_check_7020.jpg', 'frame_check_7140.jpg', 'frame_check_7200.jpg', 'frame_check_31410.jpg', 'frame_check_22920.jpg', 'frame_check_19290.jpg', 'frame_check_31470.jpg', 'frame_check_31500.jpg', 'frame_check_31530.jpg', 'frame_check_31560.jpg', 'frame_check_6330.jpg', 'frame_check_24570.jpg']\n",
      "Image: frame_check_16560.jpg have 3 Duplicates image : ['frame_check_7530.jpg', 'frame_check_26040.jpg', 'frame_check_19020.jpg']\n",
      "Image: frame_check_4080.jpg have 1 Duplicates image : ['frame_check_4140.jpg']\n",
      "Image: frame_check_17580.jpg have 2 Duplicates image : ['frame_check_6870.jpg', 'frame_check_17640.jpg']\n",
      "Image: frame_check_26850.jpg have 7 Duplicates image : ['frame_check_6990.jpg', 'frame_check_7170.jpg', 'frame_check_8760.jpg', 'frame_check_6060.jpg', 'frame_check_27360.jpg', 'frame_check_24540.jpg', 'frame_check_24660.jpg']\n",
      "Image: frame_check_7050.jpg have 1 Duplicates image : ['frame_check_7080.jpg']\n",
      "Image: frame_check_24630.jpg have 1 Duplicates image : ['frame_check_7110.jpg']\n",
      "Image: frame_check_27000.jpg have 16 Duplicates image : ['frame_check_7230.jpg', 'frame_check_7260.jpg', 'frame_check_7290.jpg', 'frame_check_7320.jpg', 'frame_check_7350.jpg', 'frame_check_27030.jpg', 'frame_check_6120.jpg', 'frame_check_6150.jpg', 'frame_check_6180.jpg', 'frame_check_6210.jpg', 'frame_check_6240.jpg', 'frame_check_6270.jpg', 'frame_check_6300.jpg', 'frame_check_19500.jpg', 'frame_check_19530.jpg', 'frame_check_19590.jpg']\n",
      "Image: frame_check_7500.jpg have 6 Duplicates image : ['frame_check_8550.jpg', 'frame_check_8610.jpg', 'frame_check_6450.jpg', 'frame_check_6570.jpg', 'frame_check_7800.jpg', 'frame_check_7830.jpg']\n",
      "Image: frame_check_17850.jpg have 2 Duplicates image : ['frame_check_26970.jpg', 'frame_check_27090.jpg']\n",
      "Image: frame_check_17880.jpg have 2 Duplicates image : ['frame_check_17940.jpg', 'frame_check_17970.jpg']\n",
      "Image: frame_check_17910.jpg have 1 Duplicates image : ['frame_check_23550.jpg']\n",
      "Image: frame_check_1800.jpg have 2 Duplicates image : ['frame_check_1830.jpg', 'frame_check_1770.jpg']\n",
      "Image: frame_check_18120.jpg have 1 Duplicates image : ['frame_check_25470.jpg']\n",
      "Image: frame_check_18150.jpg have 2 Duplicates image : ['frame_check_19320.jpg', 'frame_check_18630.jpg']\n",
      "Image: frame_check_26880.jpg have 1 Duplicates image : ['frame_check_22890.jpg']\n",
      "Image: frame_check_2700.jpg have 1 Duplicates image : ['frame_check_2730.jpg']\n",
      "Image: frame_check_31380.jpg have 1 Duplicates image : ['frame_check_20880.jpg']\n",
      "Image: frame_check_22530.jpg have 1 Duplicates image : ['frame_check_19560.jpg']\n",
      "Image: frame_check_22560.jpg have 1 Duplicates image : ['frame_check_5970.jpg']\n",
      "Image: frame_check_22590.jpg have 1 Duplicates image : ['frame_check_30000.jpg']\n",
      "Image: frame_check_0990.jpg have 2 Duplicates image : ['frame_check_0630.jpg', 'frame_check_0660.jpg']\n",
      "Image: frame_check_1020.jpg have 5 Duplicates image : ['frame_check_0840.jpg', 'frame_check_0870.jpg', 'frame_check_0900.jpg', 'frame_check_0930.jpg', 'frame_check_0960.jpg']\n",
      "Image: frame_check_10470.jpg have 1 Duplicates image : ['frame_check_10500.jpg']\n",
      "Image: frame_check_10530.jpg have 1 Duplicates image : ['frame_check_10560.jpg']\n",
      "Image: frame_check_10650.jpg have 2 Duplicates image : ['frame_check_22110.jpg', 'frame_check_22140.jpg']\n",
      "Image: frame_check_8430.jpg have 9 Duplicates image : ['frame_check_8460.jpg', 'frame_check_8490.jpg', 'frame_check_8520.jpg', 'frame_check_8640.jpg', 'frame_check_5610.jpg', 'frame_check_6090.jpg', 'frame_check_6420.jpg', 'frame_check_9120.jpg', 'frame_check_9150.jpg']\n",
      "Image: frame_check_13530.jpg have 1 Duplicates image : ['frame_check_24750.jpg']\n",
      "Image: frame_check_16500.jpg have 1 Duplicates image : ['frame_check_16530.jpg']\n",
      "Image: frame_check_16620.jpg have 1 Duplicates image : ['frame_check_17490.jpg']\n",
      "Image: frame_check_16650.jpg have 1 Duplicates image : ['frame_check_21990.jpg']\n",
      "Image: frame_check_16680.jpg have 1 Duplicates image : ['frame_check_16710.jpg']\n",
      "Image: frame_check_5580.jpg have 1 Duplicates image : ['frame_check_6390.jpg']\n",
      "Image: frame_check_5640.jpg have 2 Duplicates image : ['frame_check_6480.jpg', 'frame_check_6540.jpg']\n",
      "Image: frame_check_5730.jpg have 2 Duplicates image : ['frame_check_5760.jpg', 'frame_check_5790.jpg']\n",
      "Image: frame_check_25920.jpg have 1 Duplicates image : ['frame_check_5850.jpg']\n",
      "Image: frame_check_25500.jpg have 1 Duplicates image : ['frame_check_21180.jpg']\n",
      "Image: frame_check_1920.jpg have 1 Duplicates image : ['frame_check_1740.jpg']\n",
      "Image: frame_check_21270.jpg have 4 Duplicates image : ['frame_check_21420.jpg', 'frame_check_21240.jpg', 'frame_check_21720.jpg', 'frame_check_19650.jpg']\n",
      "Image: frame_check_21450.jpg have 2 Duplicates image : ['frame_check_21480.jpg', 'frame_check_20700.jpg']\n",
      "Image: frame_check_2160.jpg have 1 Duplicates image : ['frame_check_2190.jpg']\n",
      "Image: frame_check_21600.jpg have 2 Duplicates image : ['frame_check_30660.jpg', 'frame_check_30690.jpg']\n",
      "Image: frame_check_29940.jpg have 2 Duplicates image : ['frame_check_29970.jpg', 'frame_check_22350.jpg']\n",
      "Image: frame_check_30060.jpg have 1 Duplicates image : ['frame_check_15690.jpg']\n",
      "Image: frame_check_0480.jpg have 1 Duplicates image : ['frame_check_0540.jpg']\n",
      "Image: frame_check_0690.jpg have 3 Duplicates image : ['frame_check_0720.jpg', 'frame_check_0750.jpg', 'frame_check_0780.jpg']\n",
      "Image: frame_check_23490.jpg have 1 Duplicates image : ['frame_check_25800.jpg']\n",
      "Image: frame_check_23640.jpg have 1 Duplicates image : ['frame_check_29730.jpg']\n",
      "Image: frame_check_15390.jpg have 1 Duplicates image : ['frame_check_16140.jpg']\n",
      "Image: frame_check_21780.jpg have 5 Duplicates image : ['frame_check_21870.jpg', 'frame_check_25890.jpg', 'frame_check_26070.jpg', 'frame_check_24690.jpg', 'frame_check_18600.jpg']\n",
      "Image: frame_check_3270.jpg have 1 Duplicates image : ['frame_check_3300.jpg']\n",
      "Image: frame_check_3510.jpg have 4 Duplicates image : ['frame_check_3540.jpg', 'frame_check_3600.jpg', 'frame_check_3660.jpg', 'frame_check_3690.jpg']\n",
      "Image: frame_check_1710.jpg have 1 Duplicates image : ['frame_check_1620.jpg']\n",
      "Image: frame_check_17250.jpg have 1 Duplicates image : ['frame_check_17280.jpg']\n",
      "Image: frame_check_17700.jpg have 1 Duplicates image : ['frame_check_7590.jpg']\n",
      "Image: frame_check_25830.jpg have 1 Duplicates image : ['frame_check_18900.jpg']\n",
      "Image: frame_check_26190.jpg have 1 Duplicates image : ['frame_check_6360.jpg']\n",
      "Image: frame_check_5010.jpg have 2 Duplicates image : ['frame_check_8940.jpg', 'frame_check_7980.jpg']\n",
      "Image: frame_check_14100.jpg have 1 Duplicates image : ['frame_check_14130.jpg']\n",
      "Image: frame_check_14460.jpg have 2 Duplicates image : ['frame_check_14490.jpg', 'frame_check_14550.jpg']\n",
      "Image: frame_check_14520.jpg have 5 Duplicates image : ['frame_check_14580.jpg', 'frame_check_14610.jpg', 'frame_check_14640.jpg', 'frame_check_14670.jpg', 'frame_check_14700.jpg']\n",
      "Image: frame_check_10860.jpg have 3 Duplicates image : ['frame_check_10890.jpg', 'frame_check_11010.jpg', 'frame_check_11040.jpg']\n",
      "Image: frame_check_10920.jpg have 1 Duplicates image : ['frame_check_10950.jpg']\n",
      "Image: frame_check_10980.jpg have 4 Duplicates image : ['frame_check_11190.jpg', 'frame_check_11220.jpg', 'frame_check_11250.jpg', 'frame_check_11280.jpg']\n",
      "Image: frame_check_11100.jpg have 2 Duplicates image : ['frame_check_11130.jpg', 'frame_check_11160.jpg']\n",
      "Image: frame_check_12420.jpg have 3 Duplicates image : ['frame_check_12750.jpg', 'frame_check_12840.jpg', 'frame_check_12900.jpg']\n",
      "Image: frame_check_19680.jpg have 2 Duplicates image : ['frame_check_19740.jpg', 'frame_check_19920.jpg']\n",
      "Image: frame_check_7710.jpg have 1 Duplicates image : ['frame_check_7740.jpg']\n",
      "Image: frame_check_1860.jpg have 1 Duplicates image : ['frame_check_1890.jpg']\n",
      "Image: frame_check_20910.jpg have 1 Duplicates image : ['frame_check_20940.jpg']\n",
      "Image: frame_check_0120.jpg have 1 Duplicates image : ['frame_check_0150.jpg']\n",
      "Image: frame_check_0180.jpg have 1 Duplicates image : ['frame_check_0270.jpg']\n",
      "Image: frame_check_0210.jpg have 1 Duplicates image : ['frame_check_0240.jpg']\n",
      "Image: frame_check_11670.jpg have 1 Duplicates image : ['frame_check_11760.jpg']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "\n",
    "def find_duplicate_images(folder_path, hash_size=8):\n",
    "    hash_method = imagehash.phash \n",
    "    image_hashes = {}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            with Image.open(image_path) as img:\n",
    "                img_hash = str(hash_method(img, hash_size=hash_size))\n",
    "                if img_hash in image_hashes:\n",
    "                    image_hashes[img_hash].append(filename)\n",
    "                else:\n",
    "                    image_hashes[img_hash] = [filename]\n",
    "                    \n",
    "    duplicates = {}\n",
    "    for img_hash, filenames in image_hashes.items():\n",
    "        if len(filenames) > 1:\n",
    "            longest_name = max(filenames, key=len)\n",
    "            duplicates[longest_name] = [fname for fname in filenames if fname != longest_name]\n",
    "\n",
    "    return duplicates\n",
    "\n",
    "folder_path = '/media/tung/New Volume/Ubuntu/Programing/MQSolutions/TaskData/dataset/fire_mq_data/'\n",
    "duplicates = find_duplicate_images(folder_path)\n",
    "for img_hash, filenames in duplicates.items():\n",
    "    print(f\"Image: {img_hash} have {len(filenames)} Duplicates image : {filenames}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split images vertically\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def split_images_vertically(folder_path, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Get the list of image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    # Iterate over each image file\n",
    "    for i, image_file in enumerate(image_files):\n",
    "        # Open the image\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        with Image.open(image_path) as img:\n",
    "            # Get the width and height of the image\n",
    "            width, height = img.size\n",
    "\n",
    "            # Calculate the split position\n",
    "            split_position = width // 2\n",
    "\n",
    "            # Split the image vertically\n",
    "            left_image = img.crop((0, 0, split_position, height))\n",
    "            right_image = img.crop((split_position, 0, width, height))\n",
    "\n",
    "            # Save the split images with numbered names\n",
    "            left_image.save(os.path.join(output_folder, f\"{i+1}_left.jpg\"))\n",
    "            right_image.save(os.path.join(output_folder, f\"{i+1}_right.jpg\"))\n",
    "\n",
    "# Example usage\n",
    "folder_path = \"/media/tung/New Volume/Ubuntu/Programing/MQSolutions/TaskData/dataset/camera_tampering/results/\"\n",
    "output_folder = \"/media/tung/New Volume/Ubuntu/Programing/MQSolutions/TaskData/dataset/camera_tampering/camera_spliit_test/\"\n",
    "split_images_vertically(folder_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using ANNOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tqdm import tqdm\n",
    "from annoy import AnnoyIndex\n",
    "\n",
    "# Initialize ResNet50 model\n",
    "model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Function to extract features from an image\n",
    "def extract_features(img_path, model):\n",
    "    \"\"\"Extract features from an image using ResNet50.\"\"\"\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    expanded_img_array = np.expand_dims(img_array, axis=0)\n",
    "    preprocessed_img = preprocess_input(expanded_img_array)\n",
    "    features = model.predict(preprocessed_img)\n",
    "    flattened_features = features.flatten()\n",
    "    normalized_features = flattened_features / np.linalg.norm(flattened_features)\n",
    "    return normalized_features\n",
    "\n",
    "# Function to build an index of images\n",
    "def get_file_list(root_dir, extensions=['.jpg', '.jpeg', '.png']):\n",
    "    \"\"\"Get a list of image paths from a directory.\"\"\"\n",
    "    file_list = []\n",
    "    for root, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if any(filename.lower().endswith(ext) for ext in extensions):\n",
    "                file_list.append(os.path.join(root, filename))\n",
    "    return file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and extract features\n",
    "root_dir = '/media/tung/New Volume/Ubuntu/Programing/MQSolutions/TaskData/dataset/ads compare/TV/VIETTEL TV360 15s 0605/VIETTEL TV360 15s 0605/'\n",
    "filenames = get_file_list(root_dir)\n",
    "feature_list = [extract_features(filename, model) for filename in tqdm(filenames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100352,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Build ANNOY index\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mfeature_list\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      5\u001b[0m t \u001b[38;5;241m=\u001b[39m AnnoyIndex(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meuclidean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, feature \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(feature_list):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'feature_list' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "# Build ANNOY index\n",
    "f = len(feature_list[0])\n",
    "t = AnnoyIndex(f, 'euclidean')\n",
    "for i, feature in enumerate(feature_list):\n",
    "    t.add_item(i, feature)\n",
    "t.build(150)\n",
    "\n",
    "duplicate_threshold = 0.4 \n",
    "\n",
    "def visualize_similar_images(image_paths):\n",
    "    \"\"\"Visualize a list of images.\"\"\"\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    for i, img_path in enumerate(image_paths):\n",
    "        # img = image.load_img(img_path)\n",
    "        img = Image.open(img_path)\n",
    "        plt.subplot(1, len(image_paths), i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(os.path.basename(img_path))\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Đã xử lý hình ảnh\n",
    "processed_images = set()\n",
    "\n",
    "duplicate_images = {}  # Dictionary to store near-duplicate image groups\n",
    "\n",
    "for i in range(len(feature_list)):\n",
    "    if i in processed_images:\n",
    "        continue  # Bỏ qua nếu hình ảnh đã được xử lý\n",
    "\n",
    "    nearest_ids = t.get_nns_by_item(i, 30)  # Find the 10 nearest images\n",
    "    near_duplicates = []\n",
    "    for j in nearest_ids:\n",
    "        if i != j and np.linalg.norm(np.array(feature_list[i]) - np.array(feature_list[j])) < duplicate_threshold:\n",
    "            near_duplicates.append(filenames[j])\n",
    "            processed_images.add(j)  # Đánh dấu hình ảnh này đã được xử lý\n",
    "    \n",
    "    if near_duplicates:\n",
    "        duplicate_images[filenames[i]] = near_duplicates\n",
    "        processed_images.add(i)  # Đánh dấu hình ảnh cơ sở cũng đã được xử lý\n",
    "\n",
    "# Now visualize each group of near-duplicate images\n",
    "for base_image, duplicates in duplicate_images.items():\n",
    "    print(f\"Base Image: {base_image}\")\n",
    "    all_images = [base_image] + duplicates\n",
    "    visualize_similar_images(all_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of duplicate images: 293\n"
     ]
    }
   ],
   "source": [
    "total_duplicates = 0\n",
    "for base_image, duplicates in duplicate_images.items():\n",
    "    total_duplicates += len(duplicates)\n",
    "\n",
    "print(f\"Total number of duplicate images: {total_duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of keys in the dictionary: 30\n"
     ]
    }
   ],
   "source": [
    "duplicate_images\n",
    "num_keys = len(duplicate_images.keys())\n",
    "print(\"Number of keys in the dictionary:\", num_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    folder_path = '/media/tung/New Volume/Ubuntu/Programing/MQSolutions/TaskData/dataset/fire_mq_data'  # Cập nhật đường dẫn tới thư mục chứa ảnh\n",
    "    analyst = IssueAnalyst(folder_path)\n",
    "    results_df = analyst.analyze_images(issue_types=['dark', 'light', 'blurry', 'duplicate', 'near_duplicate'])\n",
    "    \n",
    "    # Xuất kết quả ra file CSV sử dụng PySpark\n",
    "    output_path = 'output.csv'\n",
    "    results_df.write.csv(output_path, header=True, mode='overwrite')\n",
    "\n",
    "    # Chuyển đổi PySpark DataFrame về Pandas DataFrame trên driver node để in kết quả phân tích\n",
    "    results_pd_df = results_df.toPandas()\n",
    "    \n",
    "    # In kết quả phân tích\n",
    "    print(sumary_issue(results_pd_df))  # In kết quả phân tích\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using P Hash and check by MSE and SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tdqm import tqdm\n",
    "\n",
    "def _dhash(self, image):\n",
    "    resized_img = cv2.resize(image, (self.hash_size + 1, self.hash_size))\n",
    "    diff = resized_img[:, 1:] > resized_img[:, :-1]\n",
    "    return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])\n",
    "\n",
    "def _mse(self, first_img, second_img):\n",
    "    err = np.sum((first_img.astype(\"float\") - second_img.astype(\"float\")) ** 2)\n",
    "    err /= float(first_img.shape[0] * first_img.shape[1])\n",
    "    return err\n",
    "\n",
    "def find_near_duplicate_image(self):\n",
    "    image_data = {}\n",
    "    pic_hashes = {}\n",
    "\n",
    "    for rel_path in os.listdir(self.folder_path):\n",
    "        path = os.path.join(self.folder_path, rel_path)\n",
    "        img = cv2.imread(path, 0)\n",
    "        if img is None:\n",
    "            continue\n",
    "        image_data[rel_path] = img  # Use filename instead of full path\n",
    "        image_hash = self._dhash(img)\n",
    "        pic_hashes.setdefault(image_hash, []).append(rel_path)  # Use filename instead of full path\n",
    "\n",
    "    duplicates_dict = {}\n",
    "    for hash_key, files in pic_hashes.items():\n",
    "        if len(files) > 1:\n",
    "            for i in range(len(files)):\n",
    "                for j in range(i + 1, len(files)):\n",
    "                    img1 = image_data[files[i]]\n",
    "                    img2 = image_data[files[j]]\n",
    "                    if img1.shape == img2.shape:\n",
    "                        mse_val = self._mse(img1, img2)\n",
    "                        ssim_val = ssim(img1, img2)\n",
    "                        if mse_val < 20 and ssim_val > 0.95:\n",
    "                            duplicates_dict.setdefault(files[i], []).append(files[j])\n",
    "                            duplicates_dict.setdefault(files[j], []).append(files[i])\n",
    "\n",
    "    # Filter out non-duplicates and ensure each image is listed once\n",
    "    near_duplicates = {key: list(set(values)) for key, values in duplicates_dict.items() if len(values) > 0}\n",
    "    return near_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpness Laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy import signal\n",
    "import pywt\n",
    "import scipy.stats\n",
    "from PIL import Image\n",
    "\n",
    "def eval_sharpness_laplacian(image: Image) -> float:\n",
    "    '''\n",
    "    Image sharpness metric used laplacian transform\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    image: PIL.JpegImageFile\n",
    "        Input image (3 channels)\n",
    "    \n",
    "    Returns\n",
    "    ------------\n",
    "    sharpness: float\n",
    "        Image Sharpness ratio\n",
    "    '''\n",
    "\n",
    "    # Convert the PIL.JpegImageFile object to a numpy array\n",
    "    image = np.array(image)\n",
    "\n",
    "    gray = 0.299 * image[:, :, 0] + 0.587 * image[:, :, 1] + 0.114 * image[:, :, 2]\n",
    "    gray = gaussian_filter(gray, sigma=.5)\n",
    "    kernel = np.zeros((3, 3), float)\n",
    "    kernel[1][1] = - 4\n",
    "    kernel[0][1] = 1\n",
    "    kernel[1][0] = 1\n",
    "    kernel[1][2] = 1\n",
    "    kernel[2][1] = 1\n",
    "    convoluted = np.absolute(signal.convolve2d(gray, kernel))\n",
    "    threshold = 10\n",
    "    crop = 5\n",
    "    sharpness_result = np.zeros((convoluted.shape[0], convoluted.shape[1]), np.float)\n",
    "    sharpness_result[np.where(convoluted > threshold)] = 255\n",
    "    if convoluted.shape[0] > crop * 2 and convoluted.shape[1] > crop * 2:\n",
    "        ratio = np.sum(sharpness_result[crop:convoluted.shape[0] - crop, crop:convoluted.shape[1] - crop]) / \\\n",
    "                ((convoluted.shape[0] - crop * 2) * (convoluted.shape[1] - crop * 2) + 1)\n",
    "    else:\n",
    "        ratio = np.sum(sharpness_result) / (convoluted.shape[0] * convoluted.shape[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dom import DOM\n",
    "import cv2\n",
    "\n",
    "#img = cv2.imread(\"images/image_quality_estimation/02_2sigma_blurred.tif\", 1)\n",
    "img1 = cv2.imread(\"images/image_quality_estimation/02.tif\", 1)\n",
    "img2 = cv2.imread(\"images/image_quality_estimation/02_2sigma_blurred.tif\", 1)\n",
    "img3 = cv2.imread(\"images/image_quality_estimation/02_3sigma_blurred.tif\", 1)\n",
    "img4 = cv2.imread(\"images/image_quality_estimation/02_5sigma_blurred.tif\", 1)\n",
    "\n",
    "\n",
    "# initialize DOM\n",
    "iqa = DOM()\n",
    "\n",
    "#Calculate scores\n",
    "score1 = iqa.get_sharpness(img1)\n",
    "score2 = iqa.get_sharpness(img2)\n",
    "score3 = iqa.get_sharpness(img3)\n",
    "score4 = iqa.get_sharpness(img4)\n",
    "\n",
    "print(\"Sharpness for reference image:\", score1)\n",
    "print(\"Sharpness for 2 sigma blurred image:\", score2)\n",
    "print(\"Sharpness for 3 sigma blurred image:\", score3)\n",
    "print(\"Sharpness for 5 sigma blurred image:\", score4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('/media/tung/New Volume/Ubuntu/Programing/MQ Solutions/Task Data/Data_quality_local/data/dermet_image_train/1IMG014.jpg')\n",
    "eval_sharpness_laplacian(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BRISQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "rescale() got an unexpected keyword argument 'multichannel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/media/tcb/New Volume/Ubuntu/Programing/MQSolutions/data-cleaning/dataset/ads_compare/raw_dataset/1_dataset 3/anh chup poster/VIETBANK (đủ ảnh)/101 LANG HA (45).jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m img \u001b[38;5;241m=\u001b[39m img_as_float(img)\n\u001b[0;32m---> 10\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mbrisque\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBrisque score = \u001b[39m\u001b[38;5;124m\"\u001b[39m, score)\n",
      "File \u001b[0;32m/media/tcb/New Volume/Ubuntu/Programing/MQSolutions/data-cleaning/Data_quality/venv/lib/python3.10/site-packages/imquality/brisque.py:160\u001b[0m, in \u001b[0;36mscore\u001b[0;34m(image, kernel_size, sigma)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mscore\u001b[39m(image: PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mImage, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m, sigma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m6\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     scaled_features \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m predict(scaled_features)\n",
      "File \u001b[0;32m/media/tcb/New Volume/Ubuntu/Programing/MQSolutions/data-cleaning/Data_quality/venv/lib/python3.10/site-packages/imquality/brisque.py:136\u001b[0m, in \u001b[0;36mcalculate_features\u001b[0;34m(image, kernel_size, sigma)\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 136\u001b[0m     downscaled_image \u001b[38;5;241m=\u001b[39m \u001b[43mskimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrescale\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbrisque\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mconstant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43manti_aliasing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultichannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m downscaled_brisque \u001b[38;5;241m=\u001b[39m Brisque(downscaled_image, kernel_size\u001b[38;5;241m=\u001b[39mkernel_size, sigma\u001b[38;5;241m=\u001b[39msigma)\n\u001b[1;32m    145\u001b[0m features \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mconcatenate([brisque\u001b[38;5;241m.\u001b[39mfeatures, downscaled_brisque\u001b[38;5;241m.\u001b[39mfeatures])\n",
      "File \u001b[0;32m/media/tcb/New Volume/Ubuntu/Programing/MQSolutions/data-cleaning/Data_quality/venv/lib/python3.10/site-packages/skimage/_shared/utils.py:438\u001b[0m, in \u001b[0;36mchannel_as_last_axis.__call__.<locals>.fixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    435\u001b[0m channel_axis \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannel_axis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m channel_axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;66;03m# TODO: convert scalars to a tuple in anticipation of eventually\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;66;03m#       supporting a tuple of channel axes. Right now, only an\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m#       integer or a single-element tuple is supported, though.\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(channel_axis):\n",
      "\u001b[0;31mTypeError\u001b[0m: rescale() got an unexpected keyword argument 'multichannel'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage import io, img_as_float\n",
    "import imquality.brisque as brisque\n",
    "from PIL import Image\n",
    "\n",
    "#img = img_as_float(io.imread('noisy_images/BSE.jpg', as_gray=True))\n",
    "img = Image.open(\"/media/tcb/New Volume/Ubuntu/Programing/MQSolutions/data-cleaning/dataset/ads_compare/raw_dataset/1_dataset 3/anh chup poster/VIETBANK (đủ ảnh)/101 LANG HA (45).jpg\")\n",
    "img = img_as_float(img)\n",
    "\n",
    "score = brisque.score(img)\n",
    "print(\"Brisque score = \", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
